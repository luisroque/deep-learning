{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accompanied-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "treated-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = tfd.Normal(loc=0, scale=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "alpha-creativity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-0.76491195, -1.2679604 ,  1.3671497 ], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = normal.sample(3)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-lexington",
   "metadata": {},
   "source": [
    "We are creating a normal distribution object and sampling from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "quarterly-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_and_shift = tfb.Chain([tfb.Shift(1.), tfb.Scale(2.)])\n",
    "x = scale_and_shift.forward(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-netscape",
   "metadata": {},
   "source": [
    "The, we are creating a scale and shift bijector. We are transforming the tensor z by passing it to the forward method of the bijector. The tensor x is then a scaled and shifted version of z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "local-guest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-1.9046309, -2.4159474, -2.546635 ], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob_z = normal.log_prob(z)\n",
    "log_prob_x = (normal.log_prob(z) - scale_and_shift.forward_log_det_jacobian(z, event_ndims=0))\n",
    "log_prob_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-wrestling",
   "metadata": {},
   "source": [
    "We can compute the log probability of z by simply using the log prob method of the normal distribution. We can also compute the log probability of x using the change of variables formula, as the log probility of z minus the log of the jacobian determinant of the bijector transformation evaluated at z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "rubber-catholic",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prob_x = (normal.log_prob(z) + scale_and_shift.inverse_log_det_jacobian(x, event_ndims=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-smooth",
   "metadata": {},
   "source": [
    "We can also invert the change of variables formula to express it in terms of the inverse of the bijector transformation. In that case we can write that the log probability of x is equal to the log of probability of z plus the log of the jacobian determinant of inverse transformation evaluated at x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-viking",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prob_x = (normal.log_prob(z) + scale_and_shift.inverse_log_det_jacobian(x, event_ndims=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-privacy",
   "metadata": {},
   "source": [
    "Notice that z is the image of x under the inverse transformation and so we can just replace z with the result of the bijectors inverse method applied to x. In the first approach we are computing the log probability of x only using the tensor z, while in the second we are computing the log probability of x only using the tensor x. In practice we will mostly use the second form of the change of variables formula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-mineral",
   "metadata": {},
   "source": [
    "#### Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-relaxation",
   "metadata": {},
   "source": [
    "A normalizing flow is a generative model of the data. The model assumes the following: we have a latent variable z which is distributed according the some base distribution, which we will typically assume to be something simple, like a diagonal gaussian distribution.  We assume that the data generating process first samples z from this base distribution and transforms it in some way according to a function f to produce the data sample x. For a normalizing flow the function f will be bijective or invertible. It will also be parameterized and we will learn its parameters with maximum likelihood. That means that in the training process we will have sample datapoints x and we will want to compute the log probability of x under the model. That is precisely what the expression above is doing. The log probability of x is what we aim to maximize in a training loop. The bijector object will contain the parameters that we are trying to optimize. Once the model is trained we can then sample from the model by first sample from the base distribution and then pass that sample through the bijector transformation using the forward method of the bijector. \n",
    "\n",
    "By convention, we think of the forward transformation as being used for sampling and the inverse transformation, together with the log jacobian determinant is used to compute log probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-restriction",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "unnecessary-ordinary",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = tfd.Normal(loc=0, scale=1.)\n",
    "z = normal.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-maple",
   "metadata": {},
   "source": [
    "We choose our base distribution (p0) to be a univariate standard normal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "surrounded-consultation",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = tfb.Exp()\n",
    "x = exp.forward(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-impossible",
   "metadata": {},
   "source": [
    "The transformation is implemented using the exponential bijector. We can then sample from the base distribution, pass the sample through the bijector, using the forward method and this will produce a data sample x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fatty-diana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.TransformedDistribution 'expNormal' batch_shape=[] event_shape=[] dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_normal = tfd.TransformedDistribution(normal, exp)\n",
    "log_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-incident",
   "metadata": {},
   "source": [
    "The transformed distribution object is useful to directly define the data distribution (p1) with a distribution object. The transformed distribution comes from the distributions module and the constructor has two required arguments which are the base distribution and the bijector. In this case the transformed distribution is a log normal distribution. The `Transformed Distribution object` has the same methods and properties as regular distributions. It has a batch shape and event shape, both inherited from the base distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "occupied-client",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.TransformedDistribution 'expNormal' batch_shape=[] event_shape=[] dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_normal = exp(normal)\n",
    "log_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-grill",
   "metadata": {},
   "source": [
    "Another way to create the transformed distribution is to call the bijector on the base distribution. Remember that the call method of a bijector object can be applied to another bijector, in which case it chains the bijectors together and it can be called in a tensor like object, which is the same as calling the forward method. Here we see that calling a bijector on a distribution object creates an instance of a transformed distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "veterinary-houston",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-0.63450694, -0.4306941 , -0.8849568 ], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_normal.sample()\n",
    "log_normal.log_prob(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-congress",
   "metadata": {},
   "source": [
    "Now that we have the transformed distribution object we can use the sample and log_prob methods as usual. In this case, when you sample you are sampling from the base distribution and then passing it through the bijector. When you compute the log probability the change of variables formula is being applied, which uses the inverse and the inverse log det jacobian methods on the bijector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-occasion",
   "metadata": {},
   "source": [
    "# Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "greek-insert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.MultivariateNormalDiag 'MultivariateNormalDiag' batch_shape=[] event_shape=[2] dtype=float32>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal = tfd.MultivariateNormalDiag(loc=[0,0], scale_diag=[1,1])\n",
    "normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cloudy-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_tril = [[1.,0.], [1., 1.]]\n",
    "scale = tfb.ScaleMatvecTriL(scale_tril=scale_tril)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "qualified-mixer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.TransformedDistribution 'scale_matvec_trilMultivariateNormalDiag' batch_shape=[] event_shape=[2] dtype=float32>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mvn = tfd.TransformedDistribution(normal, scale)\n",
    "mvn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-competition",
   "metadata": {},
   "source": [
    "Here we have a multivariate independent normal with event shape equal to 2. The bijector that we are using is a scalar bijector that multiplies the input by a lower triangular matrix (2x2). Then we create the transformed distribution object by passing in the mv normal distribution and the scaled bijector. Notice that the transformed distribution keeps the same shapes as the base distribution, namely the empty batch shape and the event shape of size 2.\n",
    "\n",
    "We've created a two dimensional independent normal distribution. The two dimensional random variable is then scaled by the lower triangular matrix that we defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "starting-dryer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.TransformedDistribution 'scale_matvec_trilMultivariateNormalDiag' batch_shape=[2] event_shape=[2] dtype=float32>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal = tfd.MultivariateNormalDiag(loc=[[0., 0.], [0., 0.]], scale_diag=[[1., 1.], [1., 1.]])\n",
    "\n",
    "scale_tril=[[[1., 0.], [1.,1.]], [[0.5, 0.], [-1, 0.5]]]\n",
    "scale = tfb.ScaleMatvecTriL(scale_tril=scale_tril)\n",
    "\n",
    "mvn = tfd.TransformedDistribution(normal, scale)\n",
    "mvn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-mississippi",
   "metadata": {},
   "source": [
    "In this case, the scaling factor is a ranked 3 tensor of shape (2,2,2). We are creating a batched independent standard normal for the base distribution and scaling each two dimensional random variable in the batch by the lower triangular matrix defined by the bijector. This is equivalent to defining a batched multivariate triL normal distribution using the rank 3 tensor for the scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "optional-puppy",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvn2 = tfd.MultivariateNormalTriL(loc=0, scale_tril=scale_tril)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "historical-device",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.Normal 'Normal' batch_shape=[2] event_shape=[] dtype=float32>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfd.Normal(loc=0, scale=[1.,1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-spine",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
