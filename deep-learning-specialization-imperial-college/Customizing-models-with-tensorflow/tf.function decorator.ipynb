{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alternative-northwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "certified-belfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Softmax\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import reuters\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-denver",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "romantic-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "coral-january",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom layers and model\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    \n",
    "    def __init__(self, units):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.units = units\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer='random_normal',\n",
    "                                 name='kernel')\n",
    "        self.b = self.add_weight(shape=(self.units, ),\n",
    "                                initializer='zeros',\n",
    "                                name = 'bias')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "serial-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDropout(Layer):\n",
    "    \n",
    "    def __init__(self, rate):\n",
    "        super(MyDropout, self).__init__()\n",
    "        self.rate = rate\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass for dropout layer\n",
    "        return tf.nn.dropout(inputs, rate=self.rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "thermal-macro",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "    \n",
    "    def __init__(self, units_1, units_2, units_3):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Define layers\n",
    "        self.layer_1 = MyLayer(units_1)\n",
    "        self.dropout_1 = MyDropout(0.5)\n",
    "        self.layer_2 = MyLayer(units_2)\n",
    "        self.dropout_2 = MyDropout(0.5)\n",
    "        self.layer_3 = MyLayer(units_3)\n",
    "        self.softmax = Softmax()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass\n",
    "        x = self.layer_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "portuguese-submission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.02151416 0.01286553 0.0070053  0.01153367 0.00521602 0.01271935\n",
      "  0.08934936 0.00717615 0.00727675 0.05981019 0.00623284 0.01508869\n",
      "  0.01501281 0.03297967 0.00366159 0.00559141 0.11308821 0.0235812\n",
      "  0.00568352 0.00899813 0.0315637  0.05127129 0.00512323 0.00331704\n",
      "  0.00392091 0.0330915  0.0139102  0.00904826 0.0117897  0.00870723\n",
      "  0.01833344 0.01591331 0.00833905 0.00201472 0.09817599 0.02169595\n",
      "  0.02489162 0.0025673  0.00613595 0.04979593 0.01325315 0.00602655\n",
      "  0.00205712 0.0106006  0.01272322 0.07134849]], shape=(1, 46), dtype=float32)\n",
      "Model: \"my_model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_layer_3 (MyLayer)         multiple                  640064    \n",
      "_________________________________________________________________\n",
      "my_dropout_2 (MyDropout)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_4 (MyLayer)         multiple                  4160      \n",
      "_________________________________________________________________\n",
      "my_dropout_3 (MyDropout)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_5 (MyLayer)         multiple                  2990      \n",
      "_________________________________________________________________\n",
      "softmax_1 (Softmax)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 647,214\n",
      "Trainable params: 647,214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model object\n",
    "\n",
    "model = MyModel(64, 64, 46)\n",
    "print(model(tf.ones((1, 10000))))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-muscle",
   "metadata": {},
   "source": [
    "### Load the reuters dataset and define the class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sought-banana",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mach1ne/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/home/mach1ne/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "\n",
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
    "\n",
    "class_names = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
    "   'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
    "   'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
    "   'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
    "   'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "norman-forestry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: earn\n"
     ]
    }
   ],
   "source": [
    "# Print the class of the first sample\n",
    "\n",
    "print('Label: {}'.format(class_names[train_labels[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-planner",
   "metadata": {},
   "source": [
    "### Get the dataset word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "liable-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Reuters word index\n",
    "\n",
    "word_to_index = reuters.get_word_index()\n",
    "\n",
    "inver_word_index = dict([(value, key) for (key, value) in word_to_index.items()])\n",
    "text_news = ' '.join([inver_word_index.get(i-3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dried-parking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
     ]
    }
   ],
   "source": [
    "# Print the first data example sentence\n",
    "print(text_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-subscription",
   "metadata": {},
   "source": [
    "### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "confidential-heritage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train:  (8982, 10000)\n",
      "Shape of x_test:  (2246, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Define a function that encodes the data into a 'bag of words' representation\n",
    "\n",
    "def bag_of_words(text_samples, elements=10000):\n",
    "    output = np.zeros((len(text_samples), elements))\n",
    "    for i, word in enumerate(text_samples):\n",
    "        output[i, word] = 1.\n",
    "    return output\n",
    "\n",
    "x_train = bag_of_words(train_data)\n",
    "x_test = bag_of_words(test_data)\n",
    "\n",
    "print('Shape of x_train: ', x_train.shape)\n",
    "print('Shape of x_test: ', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-income",
   "metadata": {},
   "source": [
    "### Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "interim-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categorical cross entropy loss and Adam optimizer\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "def loss(model, x, y, wd):\n",
    "    kernel_variables = []\n",
    "    for l in model.layers:\n",
    "        for w in l.weights:\n",
    "            if 'kernel' in w.name:\n",
    "                kernel_variables.append(w)\n",
    "    wd_penalty = wd * tf.reduce_sum([tf.reduce_sum(tf.square(k)) for k in kernel_variables])\n",
    "    y_ = model(x)\n",
    "    return loss_object(y_true=y, y_pred=y_) + wd_penalty\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "amateur-exception",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to compute the forward and backward pass\n",
    "\n",
    "@tf.function\n",
    "def grad(model, inputs, targets, wd):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets, wd)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "specialized-physics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Loss: 3.287, Accuracy: 48.041%\n",
      "Epoch 001: Loss: 1.902, Accuracy: 61.657%\n",
      "Epoch 002: Loss: 1.815, Accuracy: 65.843%\n",
      "Epoch 003: Loss: 1.772, Accuracy: 68.225%\n",
      "Epoch 004: Loss: 1.747, Accuracy: 69.116%\n",
      "Epoch 005: Loss: 1.725, Accuracy: 69.539%\n",
      "Epoch 006: Loss: 1.714, Accuracy: 69.751%\n",
      "Epoch 007: Loss: 1.725, Accuracy: 69.940%\n",
      "Epoch 008: Loss: 1.701, Accuracy: 70.218%\n",
      "Epoch 009: Loss: 1.693, Accuracy: 70.630%\n",
      "Duration : 36.179363\n"
     ]
    }
   ],
   "source": [
    "# Implement the training loop\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, train_labels))\n",
    "train_dataset = train_dataset.batch(32)\n",
    "\n",
    "# Keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 10\n",
    "weight_decay = 0.005\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    \n",
    "    # Training loop\n",
    "    for x, y in train_dataset:\n",
    "        # optimizer the model\n",
    "        loss_value, grads = grad(model, x, y, weight_decay)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        \n",
    "        # Compute the current loss\n",
    "        epoch_loss_avg(loss_value)\n",
    "        # Compare the predicted label to actual label\n",
    "        epoch_accuracy(to_categorical(y), model(x))\n",
    "        \n",
    "    # End epoch\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "    \n",
    "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
    "                                                               epoch_loss_avg.result(),\n",
    "                                                               epoch_accuracy.result()))\n",
    "\n",
    "print('Duration : {:3f}'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-blake",
   "metadata": {},
   "source": [
    "### Print the autograph code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "musical-pressing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__grad(model, inputs, targets, wd):\n",
      "    with ag__.FunctionScope('grad', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "        with ag__.ld(tf).GradientTape() as tape:\n",
      "            loss_value = ag__.converted_call(ag__.ld(loss), (ag__.ld(model), ag__.ld(inputs), ag__.ld(targets), ag__.ld(wd)), None, fscope)\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = (ag__.ld(loss_value), ag__.converted_call(ag__.ld(tape).gradient, (ag__.ld(loss_value), ag__.ld(model).trainable_variables), None, fscope))\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the tf.autograph.to_code to see the generated code\n",
    "\n",
    "print(tf.autograph.to_code(grad.python_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-feature",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
